{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec228ebd-d44f-4755-ab91-2463bbcbc509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import hierarchical as hrc\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78493404-154b-46bc-be3b-48ce6c97b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "g = torch.load('matricies.pth').to(device) # 'FILE_PATH' in store_matrices.py\n",
    "\n",
    "vocab_dict = tokenizer.get_vocab()\n",
    "vocab_list = [None] * (max(vocab_dict.values()) + 1)\n",
    "for word, index in vocab_dict.items():\n",
    "    vocab_list[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a0e3b49-94ae-4aa4-a11f-293993467e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15339"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list.index(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cfde6bb-7c7a-4c86-9611-1b1aea3bcd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.load(\"inv_sqrt_Cov_gamma.pth\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb9e656-27f7-46e1-b569-02eda73ff434",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv_trans = A.inverse().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71186df-f1e7-47b7-a73a-a227dd79ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47fb796-7f05-452d-827a-3e995fc14a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/animals.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "categories = ['mammal', 'bird', 'reptile', 'fish', 'amphibian', 'insect']\n",
    "animals_token, animals_ind, animals_g = hrc.get_animal_category(data, categories,  vocab_dict, g)\n",
    "\n",
    "dirs = {k: hrc.estimate_cat_dir(v, g, vocab_dict) for k, v in animals_token.items()}\n",
    "\n",
    "all_animals_tokens = [a for k, v in animals_token.items() for a in v]\n",
    "dirs.update({'animal': hrc.estimate_cat_dir(all_animals_tokens, g, vocab_dict)})\n",
    "animals_token.update({'animal': all_animals_tokens})\n",
    "\n",
    "with open(\"data/plants.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "plants_token = []\n",
    "vocab_set = set(vocab_dict.keys())\n",
    "lemmas = data[\"plant\"]\n",
    "for w in lemmas:\n",
    "    plants_token.extend(hrc.noun_to_gemma_vocab_elements(w, vocab_set))\n",
    "\n",
    "dirs.update(hrc.estimate_cat_dir(plants_token, g, vocab_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db541435-f1e3-4f95-abb6-5ba717070890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mammal': {'lda': tensor([-0.1181,  0.7374,  0.1294,  ..., -0.4211, -0.2868, -0.1180],\n",
       "         device='cuda:1'),\n",
       "  'mean': tensor([-0.0325,  0.7813,  0.2077,  ..., -0.3415, -0.2703, -0.0381],\n",
       "         device='cuda:1')},\n",
       " 'bird': {'lda': tensor([ 0.2890, -0.8864,  1.6438,  ..., -0.5996,  0.2525, -0.0193],\n",
       "         device='cuda:1'),\n",
       "  'mean': tensor([ 0.2425, -0.9359,  1.6619,  ..., -0.4542,  0.1092, -0.1407],\n",
       "         device='cuda:1')},\n",
       " 'reptile': {'lda': tensor([ 0.1402,  0.1173, -0.1522,  ...,  0.2209, -0.0624,  0.0315],\n",
       "         device='cuda:1'),\n",
       "  'mean': tensor([ 0.6738,  1.2193,  0.3772,  ...,  1.1694, -0.4623, -0.2436],\n",
       "         device='cuda:1')},\n",
       " 'fish': {'lda': tensor([-0.0961,  0.2546,  0.3447,  ...,  0.3661,  0.3973,  0.2600],\n",
       "         device='cuda:1'),\n",
       "  'mean': tensor([-0.0908,  0.3068,  0.2796,  ...,  0.3508,  0.3244,  0.1997],\n",
       "         device='cuda:1')},\n",
       " 'amphibian': {'lda': tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:1'),\n",
       "  'mean': tensor([-0.6194,  2.1964,  0.7036,  ...,  1.0147,  0.0294, -2.1691],\n",
       "         device='cuda:1')},\n",
       " 'insect': {'lda': tensor([-0.4197,  0.4090,  0.6227,  ...,  0.0599,  0.0608,  0.2814],\n",
       "         device='cuda:1'),\n",
       "  'mean': tensor([-0.2568,  0.2626,  0.7900,  ..., -0.1662,  0.0374,  0.2092],\n",
       "         device='cuda:1')},\n",
       " 'animal': {'lda': tensor([-0.0431,  0.2647,  0.5077,  ..., -0.1812,  0.0024,  0.0443],\n",
       "         device='cuda:1'),\n",
       "  'mean': tensor([ 1.7981e-04,  4.0661e-01,  5.4368e-01,  ..., -1.1303e-01,\n",
       "          -7.4259e-02, -2.0537e-02], device='cuda:1')},\n",
       " 'lda': tensor([ 0.1877,  0.3790,  0.5784,  ...,  0.1188,  0.3805, -0.3512],\n",
       "        device='cuda:1'),\n",
       " 'mean': tensor([ 0.3300,  0.3575,  0.6202,  ...,  0.1010,  0.3897, -0.3980],\n",
       "        device='cuda:1')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638f290c-3484-404e-9366-645c8b9324e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_on_animal = dirs['mammal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12109abc-f97d-4c34-abdb-001e9de57dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60704"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list.index('Paris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b14ebe0-e454-45b7-b7eb-052f29920912",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv_trans_inv = A_inv_trans.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d6dfe8f-4e9c-44da-ae24-63a134ef2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import NNsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cba514e-3d8d-46d6-83a1-3a3a40ec26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec090363-22d3-4a48-b4ef-0f44a23555c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476d93132440485688f30feb1aaa2120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LanguageModel(\n",
    "    AutoModelForCausalLM.from_pretrained('meta-llama/Meta-Llama-3-8B', device_map=torch.device(\"cuda:1\"), torch_dtype=torch.float32).eval(),\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62fd823c-3f07-45f9-99e3-00f66f2135d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "  (generator): WrapperModule()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd8bbfb6-690f-47e6-88f9-a30324d815cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_bar_animal = dirs['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fdd465a-4d64-404e-8a30-a63419f561f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00be74ba-46bb-4e5a-aa24-bf2157e194d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_probs(logits, temperature: float = 0.6, top_k: float = 50):\n",
    "    logits = logits / max(temperature, 1e-5)\n",
    "\n",
    "    if top_k is not None:\n",
    "        v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "        pivot = v.select(-1, -1).unsqueeze(-1)\n",
    "        logits = torch.where(logits < pivot, -float(\"Inf\"), logits)\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f48a5e64-07f3-4e38-a015-03c07f6cf209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_sample_one_no_sync(probs_sort): # Does multinomial sampling without a cuda synchronization\n",
    "    q = torch.empty_like(probs_sort).exponential_(1)\n",
    "    return torch.argmax(probs_sort / q, dim=-1, keepdim=True).to(dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ad0dcb4-66a4-4c7b-8634-013153c01d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(dist, greedy=False):\n",
    "    if greedy:\n",
    "        print(\"here\")\n",
    "        return dist.argmax(-1)\n",
    "    probs = logits_to_probs(dist)\n",
    "    token = multinomial_sample_one_no_sync(probs)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71b8dcb9-dc2d-48d4-b4fc-8042745fda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erase_concept(last_hidden_state, concept, A_inv_trans):\n",
    "    A_inv_trans_inv = A_inv_trans.inverse()\n",
    "    concept_unit = concept / concept.pow(2).sum().sqrt()\n",
    "    l_x = (last_hidden_state @ A_inv_trans)\n",
    "    proj_on_concept = torch.tensordot(l_x, concept_unit, dims=[[-1], [-1]]).unsqueeze(-1)\n",
    "    l_x -= (proj_on_concept @ concept_unit.unsqueeze(0))\n",
    "    hidden_state = (l_x @ A_inv_trans_inv)\n",
    "    return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a8979e3-bfc7-4d6c-9203-bc7c448f168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erase_concepts(hidden_state, A_inv_trans, dirs):\n",
    "    for key, value in dirs.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            hidden_state = erase_concept(hidden_state, value, A_inv_trans)\n",
    "        elif isinstance(value, dict):\n",
    "            hidden_state = erase_concepts(hidden_state, A_inv_trans, value)\n",
    "\n",
    "    return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f80ca3b-8092-499a-b2b8-02d116d3d874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b73c3c0b6a4f99afbd3278085ec19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = tokenizer([\"What is a dog?\"], return_tensors=\"pt\")['input_ids'].to(\"cuda:1\")\n",
    "for i in tqdm(range(10)):\n",
    "    with model.trace(tokens):\n",
    "        hidden_state = model.model.layers[-1].output[0][0, -1, :]\n",
    "        \n",
    "        # hidden_state = erase_concepts(hidden_state, A_inv_trans, {'hmm': dirs['mean']})\n",
    "        # model.model.layers[-1].output[0][0, :, :] = hidden_state\n",
    "        token = sample(model.lm_head.output[:, -1:, :]).save()\n",
    "\n",
    "    tokens= torch.cat([tokens, token.squeeze(0)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "868f1220-d038-4f38-a34c-b79c8928a8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>What is a dog? How do I know if my dog is a good\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(tokens)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3692e650-670f-462b-8819-1e90c5cf9302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>What is a dog? I mean what is a dog really? You know\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(tokens)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b97b7d6-b7d1-46b8-839a-cb8f676b4b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3613838b9826411fa10a979369297d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakIdKeyDictionary.__init__.<locals>.remove at 0x7b335656b100>\n",
      "Traceback (most recent call last):\n",
      "  File \"/datadrive/usaip/anaconda3/lib/python3.12/site-packages/torch/utils/weak.py\", line 125, in remove\n",
      "    def remove(k, selfref=ref(self)):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer([\"Dogs are \"], return_tensors=\"pt\")['input_ids'].to(\"cuda:1\")\n",
    "for i in tqdm(range(40)):\n",
    "    with model.trace(tokens):\n",
    "        hidden_state = model.model.layers[-1].output[0][0, -1, :]\n",
    "        \n",
    "        # hidden_state = erase_concepts(hidden_state, A_inv_trans, {'hmm': dirs['animal']['lda']})\n",
    "        # model.model.layers[-1].output[0][0, :, :] = hidden_state\n",
    "        token = sample(model.lm_head.output[:, -1:, :]).save()\n",
    "\n",
    "    tokens= torch.cat([tokens, token.squeeze(0)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38e389f6-ddb6-4816-9104-d13e420c8666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Dogs are mammals because they have hair, sweat glands, mammary glands, nipples, and produce milk. Dogs are also mammals because they have a four-chambered heart, which is necessary for the circulation of blood.\n"
     ]
    }
   ],
   "source": [
    "# outputs without eraseure\n",
    "print(tokenizer.batch_decode(tokens)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8f89958-1ba8-494e-9440-ea7df46d1e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Dogs are mammals because they are warm-blooded, can give live birth, have hair instead of fur, and have a four-chambered heart.\n",
      "Mammals are animals that have hair or fur and give birth to\n"
     ]
    }
   ],
   "source": [
    "# erasure with \n",
    "print(tokenizer.batch_decode(tokens)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "7218c181-3d74-478a-81e2-6dea844804ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[261], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     output \u001b[38;5;241m=\u001b[39m outputs[i]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlogits[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    output = outputs[i]\n",
    "    print(output.logits.shape)\n",
    "    output = output.logits[0, -1, :].argmax(dim=0)\n",
    "    print(tokenizer.decode(output.argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80042463-fa7b-4ea5-b6aa-a8741f70c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.logits[0, :, :].argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccda80f7-41fb-4b60-9614-61547f1bbf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question a world where you'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17dff246-022f-4c79-b955-ba0050abb86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_y = g[vocab_list.index('cat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "990c645d-a8ee-48f0-8039-46f148c5192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(size=(8, 4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "112d6aef-9523-4434-be29-b37c8dc450cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.rand(size=(4096,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "396b5177-6f08-41be-9c72-710ce9257043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1010.8303,  978.7614, 1011.8314, 1000.1763, 1009.1495, 1021.1320,\n",
       "        1005.3380, 1008.5158])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensordot(a, b, dims=[[-1], [-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "416ece20-dab1-4c63-af2d-33bb1246fa83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_dist = torch.tensordot(g, l_x, dims=([-1], [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3b34b9cd-385d-4c4c-8377-862edb224cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.1406, device='cuda:1')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "352c9dab-541f-4949-883e-c6283fbfe147",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = g_dist.topk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f68b1070-7c52-47fb-ba73-5a74d0b37549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ',', '\\n', ':', ' -', '.', ' (', '!', ' in', '-']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(indices.indices.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "683e253f-9a6e-4f0b-83f2-00e295862370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mdecode(indicies)\n",
      "File \u001b[0;32m/datadrive/usaip/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4034\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   4031\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   4032\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 4034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[1;32m   4035\u001b[0m     token_ids\u001b[38;5;241m=\u001b[39mtoken_ids,\n\u001b[1;32m   4036\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[1;32m   4037\u001b[0m     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[1;32m   4038\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4039\u001b[0m )\n",
      "File \u001b[0;32m/datadrive/usaip/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:651\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token_ids, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    650\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m [token_ids]\n\u001b[0;32m--> 651\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mdecode(token_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens)\n\u001b[1;32m    653\u001b[0m clean_up_tokenization_spaces \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    654\u001b[0m     clean_up_tokenization_spaces\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_up_tokenization_spaces\n\u001b[1;32m    657\u001b[0m )\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clean_up_tokenization_spaces:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'ids': 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135370a-5222-4774-819c-9a8b6492809e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f0464e4-b0b3-44bd-9bf2-207a4d732ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_<?'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(torch.argmax(output.logits[0, -1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05fcc47-afe2-43b7-a372-041c434391cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(20).reshape(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "624dbfe9-87df-47f5-b454-e1a6c3b71bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.arange(5).reshape(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9096259-711f-49c4-93d4-d0dbd145a897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([120, 130, 140, 150])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensordot(a, b, dims=([0], [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad5583bc-0d6b-486e-91cb-87c2dad9a9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68657703-877d-4020-83a6-e88e6d2bc330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3e70abf0-c6ca-4b8c-b016-6745c24e5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2, 3]).float()\n",
    "b = torch.tensor([2, 2]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dcfb8c82-cce7-4d7f-8ecf-0af1366114ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b/ b.pow(2).sum().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "66ff030d-2707-463d-bbc0-2b3a30ad0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_proj_on_b = a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0880437c-117b-4ca7-824e-fc5afd50a5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5355)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_proj_on_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "be9777f1-942b-4ad1-aa24-b82901e3be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "a += -1*a_proj_on_b*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "02f8f924-b416-4d0b-b66d-88d08ce33f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5000,  0.5000])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "be68bf86-cfca-40a7-8810-68e21af0c167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f279c-192e-49cf-8541-72df385b3fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
